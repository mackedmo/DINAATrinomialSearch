{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smithsonian Trinomial Search For Documents Stored in Constellate's Datasets\n",
    "This Jupyter Notebook contains programming to search for Smithsonian Trinomial instances in datasets built using Constellate's dataset builder and export the Smithsonian Trinomial and the stable url for the work containing it as a .csv file. \n",
    "\n",
    "**How this notebook functions:** With a dataset built with Constellate's dataset builder (https://constellate.org/), this notebook runs the compiled list of unigrams from a dataset through four functions that refine the data through the use of regular expressions. The first identifies all possible Smithsonian Trinomials including some Munsell numbers and other various errors that occur. The second acts as a filter to remove any remaining Munsells and the third, fourth, and fifth remove errors due to the writing.\n",
    "\n",
    "**What you need to start using this notebook:** Dataset file built using Constellate (https://constellate.org/), Jupyter Lab environment, and Python. The dataset file should be in the same file as this notebook to access it during the execution of this notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "#Regular Expression for detection of Smithsonian Format, some Munsell \n",
    "#numbers also meet this format and will be picked up by the regular \n",
    "#expression\n",
    "tri_or_munsell_re = r'[\"]{0,1}[(]{0,1}[\\[]{0,1}((([0]{1}[1-9]{1})|[1-4]{1}[0-9]{1})|[1-9]{1}|[50])[.]{0}[/]{0,1}[-]{0,1}[a-zA-Z]{2}[.]{0}[/]{0,1}[-]{0,1}\\d{1,6}[\\]]{0,1}[)]{0,1}[.]{0,1}[,]{0,1}[;]{0,1}[:]{0,1}[\"]{0,1}[*]{0,1}'\n",
    "munsell_re = r'(0|10|5)(YR|GY|BG|PB|RP)'\n",
    "to_regex = r'-to-'\n",
    "num_to_regex = r'^(9-|14-|15-|21-|29-|32-|42-)'\n",
    "by_regex = r'-by-'\n",
    "num_by_regex = r'^(8-|9-|10-|20-|23-|40-|41-|46-)'\n",
    "km_regex = r'km2'\n",
    "num_km_regex = r'^[(]?(25|41)'\n",
    "cm_regex = r'(cm|CM|Cm|-cm)'\n",
    "num_cm_regex = r'^[(]?(9|10|14|16|25|34|41)'\n",
    "mm_regex = r'(mm|mm2|MM|Mm|mm.)'\n",
    "num_mm_regex = r'^[(]?(14|15|41)'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case for Regular Expressions and Trinomial Search Algorithm\n",
    "The next cells contain tests for the Regular Expressions used to search for Trinomial in the unigram data taken from Constellate's database. The test dataframe (test_df) contains sample data based on what may be found in the unigram data and the four cells below the test data show the refinement of test_df using regular expressions. \n",
    "\n",
    "**tri_or_munsell_re:** This regular expression is used as a filter to go through the compiled unigrams from the Constellate dataset and pull hose which meet the formatting standards for Smithsonian Trinomials.\n",
    "\n",
    "**munsell_re:** This regular expression is used as a filter to remove any remaining Munsell numbers within the dataframe built from Constellate. \n",
    "\n",
    "**to_regex and num_to_regex:** Used together these two regular expressions work to filter any errors in the dataset due to written expressions like \"10-to-20 inches\" that match possible formatting for Smithsonian Trinomials. \n",
    "\n",
    "**by_regex and num_by_regex:** Used together these two regular expressions work to filter any errors in the dataset due to written expressions like \"5-by-20 inches\" that match possible formatting for Smithsonian Trinomials. \n",
    "\n",
    "**km_regex and num_km_regex, cm_regex and num_cm_regex, mm_regex and num_mm_regex:** These six regular expressions filter errors in the dataset due to common writing conventions for measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = \"\"\"text,expected_contains\n",
    "(13-AA-1242),true\n",
    "(13Aa1242),true\n",
    "13AA1242,true\n",
    "AA1242,false\n",
    "99AA1242,false\n",
    "125AA1234,false\n",
    "12FA12,true\n",
    "02Fa012,true\n",
    "02-FA-12,true\n",
    "(02-fa-12),true\n",
    "\n",
    "2.5YR6/3,false\n",
    "5YR7/4,true\n",
    "7.5YR5/8,false\n",
    "10YR4/6,true\n",
    "(2.5YR6/3),false\n",
    "(5YR7/4),true\n",
    "(7.5YR5/8),false\n",
    "(10YR4/6),true\n",
    "2.5Y7/2,false\n",
    "10Y7/2,false\n",
    "\n",
    "15-to-20,true\n",
    "10-to-30,true\n",
    "9-to-10,true\n",
    "18-to-25,true\n",
    "25-to-30,true\n",
    "42-to-10,true\n",
    "16-to-28,true\n",
    "7-to-30,true\n",
    "10-to-12,true\n",
    "30-to-12,true\n",
    "\n",
    "15-by-20,true\n",
    "10-by-30,true\n",
    "9-by-10,true\n",
    "18-by-25,true\n",
    "25-by-30,true\n",
    "42-by-10,true\n",
    "16-by-28,true\n",
    "7-by-30,true\n",
    "10-by-12,true\n",
    "30-by-12,true\n",
    "\n",
    "41km2,true\n",
    "13km2,true\n",
    "44km2,true\n",
    "14km2,true\n",
    "4km2,true\n",
    "34/km2,true\n",
    "16-km2,true\n",
    "27/km2,true\n",
    "5-km2,true\n",
    "36/km2,true\n",
    "\n",
    "41cm123,true\n",
    "20-cm3,true\n",
    "4-cm2,true\n",
    "14cm43,true\n",
    "4cm12,true\n",
    "16CM123,true\n",
    "13CM234,true\n",
    "44CM23,true\n",
    "9CM43,true\n",
    "4CM12,true\n",
    "\n",
    "41mm123,true\n",
    "13mm234,true\n",
    "2mm2,true\n",
    "14mm43,true\n",
    "4mm12,true\n",
    "41MM123,true\n",
    "13MM234,true\n",
    "44MM23,true\n",
    "15MM43,true\n",
    "4MM12,true\n",
    "\n",
    "HURLEY,false\n",
    "Map,false\n",
    "text,false\n",
    "Wis,false\n",
    "FAULKNER,false\n",
    "Institutions,false\n",
    "archae,false\n",
    "Ancient,false\n",
    "materials,false\n",
    "Tennessee,false\n",
    "\n",
    "artifact,false\n",
    "matrix,false\n",
    "remained,false\n",
    "show,false\n",
    "Johnson,false\n",
    "7001,false\n",
    "meeting,false\n",
    "Caddo,false\n",
    "challenges,false\n",
    "disturbance,false\n",
    "\"\"\"\n",
    "\n",
    "s = StringIO(test_data)\n",
    "test_df = pd.read_csv(s)\n",
    "print(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The test below shows that the regular expression defined earlier can be used \n",
    "#refine the dataframe of all different data down to only those that match \n",
    "#smithsonian trinomial formatting including some munsell numbers that match\n",
    "#this format\n",
    "\n",
    "def tri_or_munsell_re_test(test_df):\n",
    "    test_df['tested_contains'] = test_df['text'].str.match(tri_or_munsell_re)\n",
    "    assert test_df[(test_df['tested_contains']!= test_df['expected_contains'])].empty\n",
    "    \n",
    "tri_or_munsell_re_test(test_df)\n",
    "\n",
    "test_df = test_df.loc[test_df['tested_contains']== True]\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function munsell_remover removes the leftover munsells from the\n",
    "#dataframe after the first pass of the regular expression \n",
    "#tri_or_munsell_re, this function used an additional regular\n",
    "#expression, munsell_re\n",
    "\n",
    "def munsell_remover(dataframe_in):\n",
    "    munsell_filter = dataframe_in['text'].str.contains(munsell_re)\n",
    "    return dataframe_in[~munsell_filter]\n",
    "\n",
    "test_data_trinomials = munsell_remover(test_df)\n",
    "print(test_data_trinomials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function to_error_remover removes the possible errors because of \n",
    "#written measurements (ex: \"5-to-10 feet\") within text through a 2\n",
    "#step process, first to determine whether \"-to-\" is within the text \n",
    "#and the second to verify that the possible trinomial is not a state\n",
    "#with the abbreviation TO or to\n",
    "\n",
    "def to_error_remover(dataframe_in):\n",
    "    dataframe_in['to'] = dataframe_in['text'].str.contains(to_regex)\n",
    "    dataframe_in.loc[dataframe_in['text'].str.contains(num_to_regex), 'to'] = False\n",
    "    dataframe_in = dataframe_in.loc[dataframe_in['to'] == False]\n",
    "    return dataframe_in\n",
    "    \n",
    "    \n",
    "test_data_trinomials_to = to_error_remover(test_data_trinomials)\n",
    "print(test_data_trinomials_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function by_error_remover removes the possible errors because of \n",
    "#written measurements (ex: \"5-by-2 inches\") within text through a 2\n",
    "#step process, first to determine whether \"-by-\" is within the text \n",
    "#and the second to verify that the possible trinomial is not a state\n",
    "#with the abbreviation BY or by\n",
    "\n",
    "def by_error_remover(dataframe_in):\n",
    "    dataframe_in['by'] = dataframe_in['text'].str.contains(by_regex)\n",
    "    dataframe_in.loc[dataframe_in['text'].str.contains(num_by_regex), 'by'] = False\n",
    "    dataframe_in = dataframe_in.loc[dataframe_in['by'] == False]\n",
    "    return dataframe_in\n",
    "    \n",
    "    \n",
    "test_data_trinomials_by = by_error_remover(test_data_trinomials_to)\n",
    "print(test_data_trinomials_by)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function measurement_error_remover removes the possible errors due \n",
    "#to written measurements (ex: \"5km2\") within text through a 2\n",
    "#step process, first to determine whether \"km\", \"cm\", or \"mm\" is within \n",
    "#the text and the second to verify that the possible trinomial is not\n",
    "#a state with the abbreviation for a county\n",
    "\n",
    "def measurement_error_remover(dataframe_in):\n",
    "    dataframe_in['km'] = dataframe_in['text'].str.contains(km_regex)\n",
    "    dataframe_in.loc[dataframe_in['text'].str.contains(num_km_regex), 'km'] = False\n",
    "    dataframe_in = dataframe_in.loc[dataframe_in['km'] == False]\n",
    "    \n",
    "    dataframe_in['cm'] = dataframe_in['text'].str.contains(cm_regex)\n",
    "    dataframe_in.loc[dataframe_in['text'].str.contains(num_cm_regex), 'cm'] = False\n",
    "    dataframe_in = dataframe_in.loc[dataframe_in['cm'] == False]\n",
    "    \n",
    "    dataframe_in['mm'] = dataframe_in['text'].str.contains(mm_regex)\n",
    "    dataframe_in.loc[dataframe_in['text'].str.contains(num_mm_regex), 'mm'] = False\n",
    "    dataframe_in = dataframe_in.loc[dataframe_in['mm'] == False]\n",
    "\n",
    "    \n",
    "    return dataframe_in\n",
    "    \n",
    "    \n",
    "test_data_trinomials_measurement = measurement_error_remover(test_data_trinomials_by)\n",
    "print(test_data_trinomials_measurement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and Refining Possible Smithsonian Trinomials from the Constellate Dataset\n",
    "**Using this section of the notebook for your own dataset:** To use this notebook for your own dataset, first proceed to Constellate's website to build your own dataset (https://constellate.org/builder/?start=1900&end=2022). You'll download the full metadata and n-grams and replace the placeholder \"FileName.jsonl\" with your file name after extraction. An **important** note about this file: it **must** be in the same place as the file for this Jupyter Notebook to function as intended. \n",
    "\n",
    "After replacing the file name, you will run each cell block. The second cell pulls all the unigrams from the Constellate data set. Depending on the size of your dataset this may take a significant amount of time. The last five cells run the methods shown above in the test section to identify unigrams that match known formats for Smithsonian Trinomials. \n",
    "\n",
    "Each of the five cells exports a csv after the cleaning method has been applied. The names of these files can be modified for your specific data set outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##the below code opens the file for the Constellate dataset into the \n",
    "##program and copies the file to a pandas dataframe to be cleaned and\n",
    "##refined using the methods above in the test section. The first\n",
    "##parameter is the file name and should be replaced with the file name\n",
    "##of your own dataset from Constellate\n",
    "with open('FileName.jsonl', 'r') as path:\n",
    "    #create dataframe (df) from data within jsonl file from constellate\n",
    "    df = pd.read_json(path, lines=True) \n",
    "\n",
    "df = df[df['unigramCount'].notna()]\n",
    "print (df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.DataFrame()\n",
    "\n",
    "start_time = time.time() \n",
    "#Separates the unigrams into individual rows keeping the url information for\n",
    "#the article with each one\n",
    "for x in range(0,(len(df.unigramCount)-1)): \n",
    "    tempdf = pd.DataFrame.from_dict(df.at[x,'unigramCount'], orient='index')\n",
    "    tempdf.index.name='text' \n",
    "    tempdf.reset_index(inplace=True)\n",
    "\n",
    "    tempdf = tempdf.rename(columns={0: 'count'})\n",
    "    tempdf = tempdf.assign(id = df.at[x,'id'])\n",
    "    \n",
    "    #appends new dataframe (newdf) with the new rows formed from the unigram\n",
    "    #count row in original dataframe\n",
    "    newdf = newdf.append(tempdf) \n",
    "    \n",
    "end_time = time.time() #time check for entire process\n",
    "total_time = end_time - start_time\n",
    "print (total_time)\n",
    "print (newdf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These three lines below use the tri_or_munsell regular expression\n",
    "#to filter the table of unigrams compiled from the journal data\n",
    "#from constellate\n",
    "tri_or_munsell_index = newdf['text'].str.match(tri_or_munsell_re)\n",
    "tri_or_munsell_df = newdf[tri_or_munsell_index].copy()\n",
    "tri_or_munsell_df.reset_index(inplace=True)\n",
    "\n",
    "#After this step, any row that does not contain Trinomial or Munsell formatting,\n",
    "#below are shown the first ten rows of the tri_or_munsell_df\n",
    "tri_or_munsell_df.head(10)\n",
    "\n",
    "#exports the possible trinomials or munsells to a csv\n",
    "tri_or_munsell_df[['text', 'count', 'id']].to_csv(\n",
    "    'Step1PossibleTrinomials.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the below lines of code use the function munsell_remover defined in\n",
    "#the tests section to remove any remaining munsells from the data set\n",
    "trinomial_df = munsell_remover(tri_or_munsell_df)\n",
    "trinomial_df.reset_index(inplace=True)\n",
    "\n",
    "trinomial_df[['text', 'count', 'id']].to_csv(\n",
    "                'Step2TrinomialsAfterMunsellRemoved.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##the below lines of code use the function to_error_remover defined\n",
    "##in the tests section to remove any errors resulting from the use \n",
    "##of \"-to-\" within typical writing conventions\n",
    "trinomial_df_refined_to = to_error_remover(trinomial_df)\n",
    "\n",
    "\n",
    "trinomial_df_refined_to[['text','count','id']].to_csv(\n",
    "                'Step3TrinomialsWithoutPossibleToErrors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##the below lines of code use the function by_error_remover defined\n",
    "##in the tests section to remove any errors resulting from the use \n",
    "##of \"-by-\" within typical writing conventions\n",
    "trinomial_df_refined_by = by_error_remover(trinomial_df_refined_to)\n",
    "\n",
    "trinomial_df_refined_by[['text','count','id']].to_csv(\n",
    "                'Step4TrinomialsWithoutPossibleByAndToErrors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##the below lines of code use the function measurement_error_remover defined\n",
    "##in the tests section to remove any errors resulting from the use \n",
    "##of measurements within typical writing conventions\n",
    "trinomial_df_refined_measurement = measurement_error_remover(trinomial_df_refined_by)\n",
    "\n",
    "trinomial_df_refined_measurement[['text','count','id']].to_csv(\n",
    "                'Step5TrinomialsWithoutMeasurementErrors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of File\n",
    "\n",
    "At this point, there should be five files within the file location of this notebook and your dataset. The code blocks between \"Extracting and Refining Possible Smithsonian Trinomials from the Constellate Dataset\" and this \"End of File\" can be repeated for any other .jsonl files from Constellate that you may have. **You will want to change the file names for each step of output to avoid overwriting any previous files.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
